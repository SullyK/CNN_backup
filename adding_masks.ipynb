{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SullyK/CNN_backup/blob/main/adding_masks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO**:\n",
        "- I need to do the annnotations - https://www.robots.ox.ac.uk/~vgg/software/via/via_demo.html\n",
        "- Test the annotation on a smaller dataset to see how accurate the results are.\n",
        "- Maybe use the larger dataset\n",
        "- Start bg research and write up tomorrow "
      ],
      "metadata": {
        "id": "F8gfjsPsMfHz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iYpM0NF1LwE9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "import numpy as np\n",
        "from numpy import zeros\n",
        "from numpy import asarray\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XvmDGptGFB5",
        "outputId": "87d5d174-f2ce-499b-93d9-51634eb1cdfd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PMkd5UqCibM9"
      },
      "outputs": [],
      "source": [
        "# import shutil\n",
        "\n",
        "# shutil.rmtree('/content/Mask_RCNN')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNnj-o6ORP7V",
        "outputId": "cde3d91a-df1a-4e6b-9ca0-3df49ff7ace2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Mask_RCNN' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# !git clone https://github.com/matterport/Mask_RCNN\n",
        "# !git clone https://github.com/akTwelve/Mask_RCNN\n",
        "!git clone https://github.com/SullyK/Mask_RCNN.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZP4cD2WCjKhQ"
      },
      "outputs": [],
      "source": [
        "os.chdir(\"/content/Mask_RCNN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2bdb-YSooGe",
        "outputId": "3bdc0113-3d12-4fba-dc00-1c120a463e92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.29.28)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.16.2)\n",
            "Collecting tensorflow>=2.0.0\n",
            "  Using cached tensorflow-2.8.0-cp37-cp37m-manylinux2010_x86_64.whl (497.5 MB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (4.1.2.30)\n",
            "Collecting h5py\n",
            "  Using cached h5py-3.6.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (0.2.9)\n",
            "Requirement already satisfied: IPython[all] in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (5.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->-r requirements.txt (line 7)) (57.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->-r requirements.txt (line 7)) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->-r requirements.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->-r requirements.txt (line 7)) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->-r requirements.txt (line 7)) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->-r requirements.txt (line 7)) (0.24.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->-r requirements.txt (line 7)) (0.15.0)\n",
            "Collecting keras<2.9,>=2.8.0rc0\n",
            "  Using cached keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->-r requirements.txt (line 7)) (2.8.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->-r requirements.txt (line 7)) (1.32.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->-r requirements.txt (line 7)) (1.12.1)\n",
            "Collecting keras-preprocessing>=1.1.1\n",
            "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->-r requirements.txt (line 7)) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->-r requirements.txt (line 7)) (0.3.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->-r requirements.txt (line 7)) (3.7.4.3)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->-r requirements.txt (line 7)) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->-r requirements.txt (line 7)) (1.12)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->-r requirements.txt (line 7)) (1.6.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->-r requirements.txt (line 7)) (13.0.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->-r requirements.txt (line 9)) (1.5.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.0.0->-r requirements.txt (line 7)) (0.37.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0.0->-r requirements.txt (line 7)) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0.0->-r requirements.txt (line 7)) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0.0->-r requirements.txt (line 7)) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0.0->-r requirements.txt (line 7)) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0.0->-r requirements.txt (line 7)) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0.0->-r requirements.txt (line 7)) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0.0->-r requirements.txt (line 7)) (0.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->-r requirements.txt (line 7)) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->-r requirements.txt (line 7)) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->-r requirements.txt (line 7)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->-r requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->-r requirements.txt (line 7)) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->-r requirements.txt (line 7)) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->-r requirements.txt (line 7)) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->-r requirements.txt (line 7)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->-r requirements.txt (line 7)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->-r requirements.txt (line 7)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->-r requirements.txt (line 7)) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.0.0->-r requirements.txt (line 7)) (3.2.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug->-r requirements.txt (line 10)) (1.8.1.post1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 11)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 11)) (5.1.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 11)) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 11)) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 11)) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 11)) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 11)) (0.8.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 11)) (5.2.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 11)) (5.2.2)\n",
            "Requirement already satisfied: nose>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 11)) (1.3.7)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 11)) (5.6.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 11)) (4.10.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 11)) (5.3.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 11)) (0.6.0)\n",
            "Requirement already satisfied: Sphinx>=1.3 in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 11)) (1.8.6)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 11)) (7.7.0)\n",
            "Requirement already satisfied: ipyparallel in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 11)) (8.2.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython[all]->-r requirements.txt (line 11)) (0.2.5)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3->IPython[all]->-r requirements.txt (line 11)) (2.9.1)\n",
            "Requirement already satisfied: docutils<0.18,>=0.11 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3->IPython[all]->-r requirements.txt (line 11)) (0.17.1)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3->IPython[all]->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3->IPython[all]->-r requirements.txt (line 11)) (21.3)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3->IPython[all]->-r requirements.txt (line 11)) (0.7.12)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3->IPython[all]->-r requirements.txt (line 11)) (2.11.3)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3->IPython[all]->-r requirements.txt (line 11)) (2.2.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3->IPython[all]->-r requirements.txt (line 11)) (1.2.4)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel!=2.0,>=1.3->Sphinx>=1.3->IPython[all]->-r requirements.txt (line 11)) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.3->Sphinx>=1.3->IPython[all]->-r requirements.txt (line 11)) (2.0.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->IPython[all]->-r requirements.txt (line 11)) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->IPython[all]->-r requirements.txt (line 11)) (5.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from ipyparallel->IPython[all]->-r requirements.txt (line 11)) (4.63.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from ipyparallel->IPython[all]->-r requirements.txt (line 11)) (0.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from ipyparallel->IPython[all]->-r requirements.txt (line 11)) (5.4.8)\n",
            "Requirement already satisfied: pyzmq>=18 in /usr/local/lib/python3.7/dist-packages (from ipyparallel->IPython[all]->-r requirements.txt (line 11)) (22.3.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->IPython[all]->-r requirements.txt (line 11)) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->IPython[all]->-r requirements.txt (line 11)) (3.6.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->IPython[all]->-r requirements.txt (line 11)) (1.1.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat->IPython[all]->-r requirements.txt (line 11)) (4.9.2)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat->IPython[all]->-r requirements.txt (line 11)) (4.3.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat->IPython[all]->-r requirements.txt (line 11)) (21.4.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat->IPython[all]->-r requirements.txt (line 11)) (5.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat->IPython[all]->-r requirements.txt (line 11)) (0.18.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->IPython[all]->-r requirements.txt (line 11)) (0.13.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->IPython[all]->-r requirements.txt (line 11)) (1.8.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->IPython[all]->-r requirements.txt (line 11)) (0.7.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->IPython[all]->-r requirements.txt (line 11)) (1.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->IPython[all]->-r requirements.txt (line 11)) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->IPython[all]->-r requirements.txt (line 11)) (4.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->IPython[all]->-r requirements.txt (line 11)) (0.7.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->IPython[all]->-r requirements.txt (line 11)) (0.5.1)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->IPython[all]->-r requirements.txt (line 11)) (2.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->Sphinx>=1.3->IPython[all]->-r requirements.txt (line 11)) (1.1.5)\n"
          ]
        }
      ],
      "source": [
        "pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MGig9l8WktF"
      },
      "outputs": [],
      "source": [
        "!pip uninstall keras -y\n",
        "!pip uninstall keras-nightly -y\n",
        "!pip uninstall keras-Preprocessing -y\n",
        "!pip uninstall keras-vis -y\n",
        "!pip uninstall tensorflow -y\n",
        "!pip uninstall h5py -y\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjtpQltnhzz4"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.4.0\n",
        "!pip install keras\n",
        "!pip install h5py==2.10.0\n",
        "!pip install Pillow\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anPgcnbAXNLc"
      },
      "outputs": [],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REokJEPlQG6Z"
      },
      "outputs": [],
      "source": [
        "# Import Mask RCNN\n",
        "ROOT_DIR = \"/content/\"\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import utils\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "from mrcnn.model import log\n",
        "\n",
        "%matplotlib inline \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NxMfAaf5G2i7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yg-BBHDVjv6T"
      },
      "outputs": [],
      "source": [
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oo4WErJ8ZZTr"
      },
      "outputs": [],
      "source": [
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2u4RodBZnRD"
      },
      "outputs": [],
      "source": [
        "class sullyConfig(Config):\n",
        "    \"\"\"Configuration for training on the toy shapes dataset.\n",
        "    Derives from the base Config class and overrides values specific\n",
        "    to the toy shapes dataset.\n",
        "    \"\"\"\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"MASKRCNN_CONFIG\"\n",
        "\n",
        "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
        "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 1 # background + 1 shapes\n",
        "\n",
        "    # Use small images for faster training. Set the limits of the small side\n",
        "    # the large side, and that determines the image shape.\n",
        "    IMAGE_MIN_DIM = 256 #Might have to put this back in\n",
        "    IMAGE_MAX_DIM = 256\n",
        "\n",
        "    # Use smaller anchors because our image and objects are small\n",
        "    # RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
        "\n",
        "    # Reduce training ROIs per image because the images are small and have\n",
        "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
        "    # TRAIN_ROIS_PER_IMAGE = 32\n",
        "\n",
        "    # Use a small epoch since the data is simple\n",
        "    STEPS_PER_EPOCH = 500\n",
        "\n",
        "    # use small validation steps since the epoch is small\n",
        "    VALIDATION_STEPS = 100\n",
        "    \n",
        "config = sullyConfig()\n",
        "# config.BATCH_SIZE = 16\n",
        "config.display()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvqA7tbOZs18"
      },
      "outputs": [],
      "source": [
        "def get_ax(rows=1, cols=1, size=8):\n",
        "    \"\"\"Return a Matplotlib Axes array to be used in\n",
        "    all visualizations in the notebook. Provide a\n",
        "    central point to control graph sizes.\n",
        "    \n",
        "    Change the default size attribute to control the size\n",
        "    of rendered images\n",
        "    \"\"\"\n",
        "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
        "    return ax\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install scikit-image==0.16.2\n",
        "import skimage.io\n"
      ],
      "metadata": {
        "id": "Tez7bLL_obtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVFU77pmWaZX"
      },
      "outputs": [],
      "source": [
        "\n",
        "# original class\n",
        "\n",
        "# class PlantDataset(utils.Dataset):\n",
        "#   def load_dataset(self,dataset_dir,is_train=True):\n",
        "#     self.add_class(\"dataset\", 1, \"leaf\")\n",
        "\n",
        "\n",
        "#     images_dir = dataset_dir\n",
        "\n",
        "#     for filename in os.listdir(images_dir):\n",
        "#       image_id = filename[:-4] #remove the .png or w/e\n",
        "\n",
        "#       if \"rgb\" not in image_id: #check to see if it's the image(always has rgb)\n",
        "#         continue\n",
        "\n",
        "#       number = int(image_id[13:16])\n",
        "\n",
        "#       if is_train and number >= 100:\n",
        "#           continue\n",
        "\n",
        "#       if not is_train and number < 100:\n",
        "#           continue\n",
        "\n",
        "      \n",
        "      \n",
        "#       img_path = images_dir + \"/\" + filename\n",
        "#       ann_path = images_dir + \"/\" + image_id[:17] + 'bbox.csv'\n",
        "\n",
        "#       self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
        "\n",
        "\n",
        "#   def extract_boxes(self,filename):\n",
        "#     file = open(filename)\n",
        "#     with open(filename, 'r') as csvfile:\n",
        "#       reader = csv.reader(csvfile)\n",
        "#       boxes = []\n",
        "#       for row in reader:\n",
        "#         row = [int(i) for i in row]\n",
        "#         x_max = max(row[1],row[3],row[5],row[7])\n",
        "#         x_min = min(row[1],row[3],row[5],row[7])\n",
        "#         assert x_max >= x_min #xmax is always equal to or greater than x_min\n",
        "#         y_max = max(row[2],row[4],row[6],row[8])\n",
        "#         y_min = min(row[2],row[4],row[6],row[8])\n",
        "#         assert y_max >= y_min #ymax is always equal to or greater than y_min\n",
        "\n",
        "#         coors = [x_min,y_min,x_max,y_max]\n",
        "#         boxes.append(coors)\n",
        "#         image_name = filename[:-8] + \"rgb.png\"\n",
        "#         image = PIL.Image.open(image_name)\n",
        "#         width, height = image.size\n",
        "#         # print(\"width\" + width)\n",
        "\n",
        "#         # print(boxes)\n",
        "\n",
        "#       return boxes,width,height\n",
        "\n",
        "#   def load_mask(self,image_id):\n",
        "#     info = self.image_info[image_id]\n",
        "#     path = info['annotation']\n",
        "#     boxes, w,h = self.extract_boxes(path)\n",
        "#     masks = zeros([h, w, len(boxes)], dtype='uint8')\n",
        "#     class_ids = list()\n",
        "#     for i in range(len(boxes)):\n",
        "#       box = boxes[i]\n",
        "#       row_s, row_e = int(box[1]), int(box[3])\n",
        "#       col_s, col_e = int(box[0]), int(box[2])\n",
        "#       masks[row_s:row_e, col_s:col_e, i] = 1\n",
        "#       class_ids.append(self.class_names.index('leaf'))\n",
        "#     return masks, asarray(class_ids, dtype='int32')\n",
        "\n",
        "#   def image_reference(self, image_id):\n",
        "#       info = self.image_info[image_id]\n",
        "#       print(info)\n",
        "#       return info['path']\n",
        "\n",
        "#   #--------\n",
        "\n",
        "#   # img_name = \"ara2012_plant007_rgb\"\n",
        "#   # img = skimage.io.imread(\"/content/drive/MyDrive/Plant/Ara2012/ara2012_plant007_rgb.png\")\n",
        "\n",
        "\n",
        "#   # fig, ax = matplotlib.pyplot.subplots()\n",
        "#   # ax.imshow(img)\n",
        "\n",
        "#   # string_boxes = extract_boxes(\"/content/drive/MyDrive/Plant/Ara2012/ara2012_plant007_bbox.csv\")\n",
        "#   # print(string_boxes[0][0])\n",
        "  \n",
        "\n",
        "\n",
        "#   #debug bboxes\n",
        "#   # x = []\n",
        "#   # for i in string_boxes[0][4]:\n",
        "#   #   print(i)\n",
        "#   #   x.append(int(i))\n",
        "  \n",
        "#   # # rect = matplotlib.patches.Rectangle(((x[0]),x[1]),\n",
        "#   # #                                     x[2] - x[0],\n",
        "#   # #                                     x[3]-x[1],\n",
        "#   # #                                     linewidth=1, \n",
        "#   # #                                     edgecolor='r', \n",
        "#   # #                                     facecolor='none')\n",
        "\n",
        "\n",
        "\n",
        "#   # ax.add_patch(rect)\n",
        "\n",
        "#   # matplotlib.pyplot.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# #Using the massive dataset:\n",
        "\n",
        "\n",
        "# class PlantDataset(utils.Dataset):\n",
        "#   def load_dataset(self,dataset_dir,is_train=True):\n",
        "#     self.add_class(\"dataset\", 1, \"leaf\")\n",
        "\n",
        "\n",
        "#     images_dir = dataset_dir\n",
        "\n",
        "#     for filename in os.listdir(images_dir):\n",
        "#       image_id = filename[:-4] #remove the .png or w/e\n",
        "\n",
        "#       # if \"rgb\" not in image_id: #check to see if it's the image(always has rgb)\n",
        "#       #   continue\n",
        "#       print(image_id)\n",
        "#       number = image_id[5:9]\n",
        "#       number = int(number)\n",
        "#       print(number)\n",
        "#       if is_train and number >= 1000:\n",
        "#           continue\n",
        "\n",
        "#       if not is_train and number < 1000:\n",
        "#           continue\n",
        "\n",
        "#       print(f\"filename {filename}\")\n",
        "      \n",
        "#       string_csv = '.csv'\n",
        "#       img_path = images_dir + \"/\" + image_id + '.jpg'\n",
        "#       print(img_path)\n",
        "#       ann_path = images_dir + \"/\" + image_id + '.csv'\n",
        "#       # print(ann_path)\n",
        "\n",
        "#       self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
        "\n",
        "\n",
        "#   def extract_boxes(filename):\n",
        "#     file = open(filename)\n",
        "#     with open(filename, 'r') as csvfile:\n",
        "#       reader = csv.reader(csvfile)\n",
        "#       boxes = []\n",
        "#       for row in reader:\n",
        "#         row = row[1:5]\n",
        "#         row = [int(i) for i in row]\n",
        "\n",
        "#         coors = [row[0],row[1],row[2],row[3]]\n",
        "#         boxes.append(coors)\n",
        "#         image_name = filename.replace('csv','jpg')\n",
        "#         print(boxes)\n",
        "\n",
        "#         image = PIL.Image.open(image_name)\n",
        "#         width, height = image.size\n",
        "#         # print(width)\n",
        "#         # print(height)\n",
        "\n",
        "\n",
        "#       return boxes,width,height\n",
        "\n",
        "#   def load_mask(self,image_id):\n",
        "#     info = self.image_info[image_id]\n",
        "#     path = info['annotation']\n",
        "#     boxes, w,h = self.extract_boxes(path)\n",
        "#     masks = zeros([h, w, len(boxes)], dtype='uint8')\n",
        "#     class_ids = list()\n",
        "#     for i in range(len(boxes)):\n",
        "#       box = boxes[i]\n",
        "#       row_s, row_e = int(box[1]), int(box[3])\n",
        "#       col_s, col_e = int(box[0]), int(box[2])\n",
        "#       masks[row_s:row_e, col_s:col_e, i] = 1\n",
        "#       class_ids.append(self.class_names.index('leaf'))\n",
        "#     return masks, asarray(class_ids, dtype='int32')\n",
        "\n",
        "#   def image_reference(self, image_id):\n",
        "#       info = self.image_info[image_id]\n",
        "#       print(info)\n",
        "#       return info['path']\n",
        "\n",
        "#   #--------\n",
        "\n",
        "\n",
        "#   # img_name = \"ara2012_plant007_rgb\"\n",
        "#   img = skimage.io.imread(\"/content/drive/MyDrive/plant_set/LEAF_0762.jpg\")\n",
        "\n",
        "\n",
        "#   fig, ax = matplotlib.pyplot.subplots()\n",
        "#   ax.imshow(img)\n",
        "\n",
        "#   string_boxes = extract_boxes(\"/content/drive/MyDrive/plant_set/LEAF_0762.csv\")\n",
        "#   print(string_boxes[0][0])\n",
        "\n",
        "#   # # debug bboxes\n",
        "#   x = []\n",
        "#   for i in string_boxes[0][0]:\n",
        "#     print(i)\n",
        "#     x.append(int(i))\n",
        "  \n",
        "#   rect = matplotlib.patches.Rectangle(((x[0]),x[1]),\n",
        "#                                       x[2],\n",
        "#                                       x[3],\n",
        "#                                       linewidth=1, \n",
        "#                                       edgecolor='r', \n",
        "#                                       facecolor='none')\n",
        "\n",
        "\n",
        "\n",
        "#   ax.add_patch(rect)\n",
        "\n",
        "#   matplotlib.pyplot.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iZ0_UWoUcZRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class PlantDataset(utils.Dataset):\n",
        "  def load_dataset(self,dataset_dir,is_train=True):\n",
        "    self.add_class(\"dataset\", 1, \"leaf\")\n",
        "\n",
        "\n",
        "    images_dir = dataset_dir\n",
        "\n",
        "    for filename in os.listdir(images_dir):\n",
        "      image_id = filename[:-4] #remove the .png or w/e\n",
        "\n",
        "      if \"rgb\" not in image_id: #check to see if it's the image(always has rgb)\n",
        "        continue\n",
        "\n",
        "      number = int(image_id[13:16])\n",
        "\n",
        "      if is_train and number >= 100:\n",
        "          continue\n",
        "\n",
        "      if not is_train and number < 100:\n",
        "          continue\n",
        "\n",
        "      \n",
        "      \n",
        "      img_path = images_dir + \"/\" + filename\n",
        "      # ann_path = images_dir + \"/\" + image_id[:17] + '.png'\n",
        "      ann_path = images_dir + \"/\" + image_id[:17] + 'label.png'\n",
        "\n",
        "      self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
        "\n",
        "\n",
        "  def extract_boxes(self,filename):\n",
        "    file = open(filename)\n",
        "    with open(filename, 'r') as csvfile:\n",
        "      reader = csv.reader(csvfile)\n",
        "      boxes = []\n",
        "      for row in reader:\n",
        "        row = [int(i) for i in row]\n",
        "        x_max = max(row[1],row[3],row[5],row[7])\n",
        "        x_min = min(row[1],row[3],row[5],row[7])\n",
        "        assert x_max >= x_min #xmax is always equal to or greater than x_min\n",
        "        y_max = max(row[2],row[4],row[6],row[8])\n",
        "        y_min = min(row[2],row[4],row[6],row[8])\n",
        "        assert y_max >= y_min #ymax is always equal to or greater than y_min\n",
        "\n",
        "        coors = [x_min,y_min,x_max,y_max]\n",
        "        boxes.append(coors)\n",
        "        image_name = filename[:-8] + \"rgb.png\"\n",
        "        image = PIL.Image.open(image_name)\n",
        "        width, height = image.size\n",
        "        # print(\"width\" + width)\n",
        "\n",
        "        # print(boxes)\n",
        "\n",
        "      return boxes,width,height\n",
        "\n",
        "  # def load_mask(self,image_id):\n",
        "  #   info = self.image_info[image_id]\n",
        "  #   print(\"yayyyyyy info :\", info)\n",
        "  #   path = info['annotation']\n",
        "  #   print(\"oooooo path :\", path)\n",
        "\n",
        "  #   boxes, w,h = self.extract_boxes(path)\n",
        "  #   masks = zeros([h, w, len(boxes)], dtype='uint8')\n",
        "  #   class_ids = list()\n",
        "  #   for i in range(len(boxes)):\n",
        "  #     box = boxes[i]\n",
        "  #     row_s, row_e = int(box[1]), int(box[3])\n",
        "  #     col_s, col_e = int(box[0]), int(box[2])\n",
        "  #     masks[row_s:row_e, col_s:col_e, i] = 1\n",
        "  #     class_ids.append(self.class_names.index('leaf'))\n",
        "  #   return masks, asarray(class_ids, dtype='int32')\n",
        "\n",
        "\n",
        "\n",
        "  def load_mask(self, image_id):\n",
        "    \"\"\"Generate instance masks for an image.\n",
        "    Returns:\n",
        "    masks: A bool array of shape [height, width, instance count] with\n",
        "        one mask per instance.\n",
        "    class_ids: a 1D array of class IDs of the instance masks.\n",
        "    \"\"\"\n",
        "    info = self.image_info[image_id]\n",
        "    # Get mask directory from image path\n",
        "    mask_dir = info['annotation']\n",
        "\n",
        "    # Read mask files from .png image\n",
        "    # mask = []\n",
        "    # for f in next(os.walk(mask_dir))[2]:\n",
        "    #     if f.endswith(\".png\"):\n",
        "    # m = skimage.io.imread(mask_dir).astype(np.bool)\n",
        "    # mask.append(m)\n",
        "\n",
        "    mask = skimage.io.imread(mask_dir).astype(np.bool)\n",
        "    # mask = np.stack(mask, axis=-1)\n",
        "    # Return mask, and array of class IDs of each instance. Since we have\n",
        "    # one class ID, we return an array of ones\n",
        "    return mask, np.ones([mask.shape[-1]], dtype=np.int32)\n",
        "\n",
        "\n",
        "  def image_reference(self, image_id):\n",
        "      info = self.image_info[image_id]\n",
        "      print(info)\n",
        "      return info['path']\n",
        "\n",
        "  #--------\n",
        "\n",
        "  # img_name = \"ara2012_plant007_rgb\"\n",
        "  # img = skimage.io.imread(\"/content/drive/MyDrive/Plant/Ara2012/ara2012_plant007_rgb.png\")\n",
        "\n",
        "\n",
        "  # fig, ax = matplotlib.pyplot.subplots()\n",
        "  # ax.imshow(img)\n",
        "\n",
        "  # string_boxes = extract_boxes(\"/content/drive/MyDrive/Plant/Ara2012/ara2012_plant007_bbox.csv\")\n",
        "  # print(string_boxes[0][0])\n",
        "  \n",
        "\n",
        "\n",
        "  #debug bboxes\n",
        "  # x = []\n",
        "  # for i in string_boxes[0][4]:\n",
        "  #   print(i)\n",
        "  #   x.append(int(i))\n",
        "  \n",
        "  # # rect = matplotlib.patches.Rectangle(((x[0]),x[1]),\n",
        "  # #                                     x[2] - x[0],\n",
        "  # #                                     x[3]-x[1],\n",
        "  # #                                     linewidth=1, \n",
        "  # #                                     edgecolor='r', \n",
        "  # #                                     facecolor='none')\n",
        "\n",
        "\n",
        "\n",
        "  # ax.add_patch(rect)\n",
        "\n",
        "  # matplotlib.pyplot.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gnRD1p2uDmJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJJn1mvwVYXy"
      },
      "outputs": [],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVP7qq-waFPp"
      },
      "outputs": [],
      "source": [
        "# # Training dataset\n",
        "# train_set = PlantDataset()\n",
        "# train_set.load_dataset('/content/drive/MyDrive/Plant/Ara2012', is_train=True)\n",
        "# train_set.prepare()\n",
        "# print('training set: %d' % len(train_set.image_ids))\n",
        "\n",
        "# # prepare test/val set\n",
        "# test_set = PlantDataset()\n",
        "# test_set.load_dataset('/content/drive/MyDrive/Plant/Ara2012', is_train=False)\n",
        "# test_set.prepare()\n",
        "# print('Test: %d' % len(test_set.image_ids))\n",
        "\n",
        "\n",
        "# #It has 61, should fix this..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from os import listdir\n",
        "# from PIL import Image\n",
        "\n",
        "# dir_path = \"/content/drive/MyDrive/plant_set/\"\n",
        "\n",
        "\n",
        "# for filename in listdir(dir_path):\n",
        "#     if filename.endswith('.jpg'):\n",
        "#         try:\n",
        "#             img = Image.open(dir_path+\"/\"+filename) # open the image file\n",
        "#             img.verify() # verify that it is, in fact an image\n",
        "#         except (IOError, SyntaxError) as e:\n",
        "#             print('Bad file:', filename)\n",
        "#             #os.remove(base_dir+\"\\\\\"+filename) (Maybe)\n"
      ],
      "metadata": {
        "id": "nDnUsfO0rjIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #big dataset\n",
        "\n",
        "# # Training dataset\n",
        "# train_set = PlantDataset()\n",
        "# train_set.load_dataset('/content/drive/MyDrive/plant_set', is_train=True)\n",
        "# train_set.prepare()\n",
        "# print('training set: %d' % len(train_set.image_ids))\n",
        "\n",
        "# # prepare test/val set\n",
        "# test_set = PlantDataset()\n",
        "# test_set.load_dataset('/content/drive/MyDrive/plant_set', is_train=False)\n",
        "# test_set.prepare()\n",
        "# print('Test: %d' % len(test_set.image_ids))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lNaAADuH23aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Training dataset\n",
        "train_set = PlantDataset()\n",
        "train_set.load_dataset('/content/drive/MyDrive/Plant/Ara2012', is_train=True)\n",
        "train_set.prepare()\n",
        "print('training set: %d' % len(train_set.image_ids))\n",
        "\n",
        "# prepare test/val set\n",
        "test_set = PlantDataset()\n",
        "test_set.load_dataset('/content/drive/MyDrive/Plant/Ara2012', is_train=False)\n",
        "test_set.prepare()\n",
        "print('Test: %d' % len(test_set.image_ids))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U7W3x11ioTGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_ids = np.random.choice(train_set.image_ids, 20)\n",
        "for image_id in image_ids:\n",
        "    print(image_id)\n",
        "    image = train_set.load_image(image_id)\n",
        "    mask, class_ids = train_set.load_mask(image_id)\n",
        "    visualize.display_top_masks(image, mask, class_ids, train_set.class_names)\n"
      ],
      "metadata": {
        "id": "PNlM9oUbj3ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gK3dVVFMaMGZ"
      },
      "outputs": [],
      "source": [
        "# # Load and display random samples\n",
        "# image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
        "# for image_id in image_ids:\n",
        "#     image = dataset_train.load_image(image_id)\n",
        "#     mask, class_ids = dataset_train.load_mask(image_id)\n",
        "#     visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AE00uI3Zty6"
      },
      "outputs": [],
      "source": [
        "print(\"Loading Mask R-CNN model...\")\n",
        "\n",
        "model = modellib.MaskRCNN(mode=\"training\", config=config, \n",
        "                          model_dir='./')\n",
        "os.getcwd()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqAc9ch9aKIQ"
      },
      "outputs": [],
      "source": [
        "#load the weights for COCO\n",
        "model.load_weights('/content/mask_rcnn_coco.h5', \n",
        "                   by_name=True, \n",
        "                   exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTGGOfBcp13q"
      },
      "outputs": [],
      "source": [
        "# model.train(train_set, test_set, learning_rate=0.0001, epochs=50, layers=\"heads\")\n",
        "# history = model.keras_model.history.history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gx07gA5HaiHd"
      },
      "outputs": [],
      "source": [
        "model_path = '/content/Mask_RCNN/maskrcnn_config20220407T1802/mask_rcnn_maskrcnn_config_0022.h5'\n",
        "model.keras_model.save_weights(model_path)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ve5TTXWbayUJ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "#Loading the model in the inference mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir='./')\n",
        "# loading the trained weights o the custom dataset\n",
        "model.load_weights(model_path, by_name=True)\n",
        "img = load_img('/content/drive/MyDrive/Plant/Ara2012/ara2012_plant111_rgb.png')\n",
        "img = img_to_array(img)\n",
        "# detecting objects in the image\n",
        "result= model.detect([img])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsixA9tpGMgI"
      },
      "outputs": [],
      "source": [
        "image_id = 10\n",
        "image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(test_set, config, image_id)\n",
        "info = test_set.image_info[image_id]\n",
        "print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id, \n",
        "                                       test_set.image_reference(image_id)))\n",
        "# Run object detection\n",
        "results = model.detect([image], verbose=1)\n",
        "# Display results\n",
        "\n",
        "r = results[0]\n",
        "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            test_set.class_names, r['scores'], \n",
        "                            title=\"Predictions\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WI7oavOsa5YM"
      },
      "outputs": [],
      "source": [
        "# # Test on a random image\n",
        "# image_id = random.choice(dataset_val.image_ids)\n",
        "# original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "#     modellib.load_image_gt(dataset_val, inference_config, \n",
        "#                            image_id, use_mini_mask=False)\n",
        "# # \n",
        "# log(\"original_image\", original_image)\n",
        "# log(\"image_meta\", image_meta)\n",
        "# log(\"gt_class_id\", gt_class_id)\n",
        "# log(\"gt_bbox\", gt_bbox)\n",
        "# log(\"gt_mask\", gt_mask)\n",
        "\n",
        "# visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "#                             dataset_train.class_names, figsize=(8, 8))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4V6BTCgAa7L2"
      },
      "outputs": [],
      "source": [
        "# results = model.detect([original_image], verbose=1)\n",
        "\n",
        "# r = results[0]\n",
        "# # visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "#                             dataset_val.class_names, r['scores'], ax=get_ax())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmmJvSBSaBni"
      },
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "collab_pro_final_project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}